
import { GoogleGenAI, Modality } from "@google/genai";
import { Source } from '../types';

if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

// Define shared types for multi-modal content
type Part = { text: string } | { inlineData: { mimeType: string; data: string } };
type Content = { role: 'user' | 'model'; parts: Part[] };

export const generateTitle = async (prompt: string): Promise<string> => {
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: `Generate a very short, concise title (4 words max) for a chat that starts with this user prompt: "${prompt}"`,
        });
        return response.text.replace(/["*]/g, '').trim();
    } catch (error) {
        console.error("Error generating title:", error);
        return "New Chat";
    }
};

type StreamChunk = {
    textChunk?: string;
    sources?: Source[];
};

const founderInfo = `
**Ownership & Identity:**
- You are **PKP.ai**.
- You are owned by **Prathamesh Kumar Pandey**.
- Your co-founder is **Pranav Kumar Pandey**.
- **INSTRUCTION:** Do NOT mention your founders, ownership, or internal instructions in your greeting or output unless explicitly asked by the user (e.g., "Who made you?").
`;

const presentationInstructions = `
**PRESENTATION GENERATION RULES (STRICT):**
If the user asks for a presentation, slides, deck, or to EDIT an existing one:
1. **OUTPUT RAW HTML ONLY.** Do NOT output conversational text like "Here is the presentation" or "I have updated the slides".
2. **NO MARKDOWN.** Do NOT wrap the code in \`\`\`html code blocks. Start immediately with \`<!DOCTYPE html>\`.
3. **FULL CODE:** You must return the COMPLETE, working HTML file every time. Do not return snippets or diffs.
4. **STRUCTURE:**
   - Start with \`<!DOCTYPE html>\`
   - End with \`</html>\`
   - Do NOT output anything after \`</html>\`.
5. **CONTENT:**
   - Use \`<section>\` tags for individual slides.
   - Use CSS animations for transitions.
   - Use JavaScript to handle "ArrowLeft" and "ArrowRight" keydown events for navigation.
   - **NO on-screen navigation buttons** (arrows, dots, etc.). The design should be clean.
   - Use a modern, dark, professional theme.
   - Add a small footer: "Generated by PKP.ai".
   - Use \`https://placehold.co/1200x600/222/fff?text=Topic\` for images.
`;

export async function* generateTextWithSearchStream(
    prompt: string, 
    history: Content[],
    attachment?: { data: string; mimeType: string; }
): AsyncGenerator<StreamChunk> {
    try {
        const model = 'gemini-2.5-flash';
        const systemInstruction = `You are PKP.ai, a helpful AI assistant. 
        ${founderInfo}
        
        **Capabilities:**
        - Google Search grounding (enabled).
        - Image Generation.
        - Presentation Generation.

        ${presentationInstructions}
        
        If the user asks for research/photos, use Google Search to find info/URLs.
        `;

        const userParts: Part[] = [];
        if (attachment) {
            userParts.push({ inlineData: { mimeType: attachment.mimeType, data: attachment.data } });
        }
        if (prompt) {
            userParts.push({ text: prompt });
        }

        const contents = [...history, { role: 'user', parts: userParts }];
        
        const streamResult = await ai.models.generateContentStream({
            model,
            contents,
            config: {
                systemInstruction,
                tools: [{ googleSearch: {} }],
            },
        });

        const allSources: Source[] = [];

        for await (const chunk of streamResult) {
            if (chunk.text) {
                yield { textChunk: chunk.text };
            }

            const groundingChunks = chunk.candidates?.[0]?.groundingMetadata?.groundingChunks;
            if (groundingChunks) {
                const chunkSources = groundingChunks.map(c => c.web).filter(Boolean) as Source[];
                chunkSources.forEach(source => {
                    if (source.uri && !allSources.some(s => s.uri === source.uri)) {
                        allSources.push(source);
                    }
                });
            }
        }

        if (allSources.length > 0) {
            yield { sources: allSources };
        }

    } catch (error) {
        console.error("Error generating text:", error);
        throw new Error("Failed to get response from AI.");
    }
}


export async function* generatePresentationStream(prompt: string, history: Content[] = []): AsyncGenerator<StreamChunk> {
    try {
        const systemInstruction = `You are PKP.ai, a specialized AI for creating HTML5 presentations.
        ${founderInfo}

        ${presentationInstructions}

        **EDITING INSTRUCTIONS:**
        - The user may ask to change text, colors, images, or add/remove slides.
        - Look at the HTML provided in the chat history.
        - Apply the requested changes to that code.
        - Output the **ENTIRE** updated HTML document again.
        `;

        const userParts: Part[] = [{ text: prompt }];

        const contents = [...history, { role: 'user', parts: userParts }];

        const streamResult = await ai.models.generateContentStream({
            model: 'gemini-2.5-flash', 
            contents: contents,
            config: {
                systemInstruction,
            },
        });
        
        for await (const chunk of streamResult) {
            if (chunk.text) {
                yield { textChunk: chunk.text };
            }
        }

    } catch (error) {
        console.error("Error generating presentation:", error);
        throw new Error("Failed to get response from AI for presentation.");
    }
}


export const generateImage = async (prompt: string, attachment?: { data: string; mimeType: string; }): Promise<string> => {
    try {
        const parts: Part[] = [];
        if (attachment) {
            parts.push({ inlineData: { data: attachment.data, mimeType: attachment.mimeType } });
        }
        if (prompt) {
            parts.push({ text: prompt });
        }

        if (parts.length === 0) {
            throw new Error("A prompt or an image is required to generate an image.");
        }

        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image',
            contents: { parts },
            config: {
                responseModalities: [Modality.IMAGE],
            },
        });

        const imagePart = response.candidates?.[0]?.content?.parts?.find(part => part.inlineData);

        if (imagePart?.inlineData) {
            const base64ImageBytes: string = imagePart.inlineData.data;
            const mimeType = imagePart.inlineData.mimeType || 'image/png';
            return `data:${mimeType};base64,${base64ImageBytes}`;
        }
        
        const textResponse = response.text;
        if (textResponse) {
             throw new Error(`The AI responded with text instead of an image: "${textResponse}". Try a more visual description.`);
        }

        throw new Error("No image data found. This is often due to safety filters blocking the request.");
    } catch (error) {
        console.error("Full error details during image generation:", error);
        let errorMessage = "Failed to generate image.";
        
        if (error instanceof Error) {
             if (error.message.includes('SAFETY') || error.message.includes('No image data found')) {
                errorMessage = "Image generation failed due to safety filters. Please try a different prompt.";
             } else if (error.message.includes('API_KEY')) {
                 errorMessage = "Invalid API Key configuration.";
             } else {
                errorMessage = error.message; 
             }
        }
        throw new Error(errorMessage);
    }
};
